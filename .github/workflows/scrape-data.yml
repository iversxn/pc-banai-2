name: Scrape Data

on:
  workflow_dispatch: # Allows manual triggering
  schedule:
    - cron: '0 0 * * *' # Runs at midnight UTC every day

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    # This is the new, critical step to disable IPv6 for the runner
    - name: Disable IPv6
      run: |
        sudo sysctl -w net.ipv6.conf.all.disable_ipv6=1
        sudo sysctl -w net.ipv6.conf.default.disable_ipv6=1
        sudo sysctl -w net.ipv6.conf.lo.disable_ipv6=1

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r pc-banai/scraper/requirements.txt

    - name: Run scraper
      # This now uses the secret you created
      env:
        POSTGRES_URL: ${{ secrets.POSTGRES_URL }}
      run: python pc-banai/scraper/scraper.py
